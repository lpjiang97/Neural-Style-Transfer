{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Neural Transfer Style\n",
    "\n",
    "## implementation of [Johnson et al.](https://cs.stanford.edu/people/jcjohns/eccv16/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define style and content loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram(x):\n",
    "    batch, channel, width, height = x.size()\n",
    "    # flatten features\n",
    "    x = x.view(batch * channel, width * height)\n",
    "    # gram matrix \n",
    "    G = torch.mm(x, x.t())\n",
    "    # normalize\n",
    "    return G.div(batch * channel * width * height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# override loss as a module\n",
    "class StyleLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, target):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.target = gram(target)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Gram matrix is defined as the gram matrix of all vectors\n",
    "        self.loss = F.mse_loss(self.target, gram(x))\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, target):\n",
    "        super(ContentLoss, self).__init__()\n",
    "        self.target = target\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.loss = F.mse_loss(self.target, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define loss network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 256\n",
    "\n",
    "loader = transforms.Compose([\n",
    "             transforms.Resize((imsize, imsize)),\n",
    "             transforms.ToTensor()\n",
    "         ])\n",
    "\n",
    "unloader = transforms.ToPILImage()\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = Variable(loader(image))\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "  \n",
    "def save_image(input, path):\n",
    "    image = input.data.clone().cpu()\n",
    "    image = image.view(3, imsize, imsize)\n",
    "    image = unloader(image)\n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossNet():\n",
    "    \n",
    "    def __init__(self, x, content, style, style_weight=100000, content_weight=1):\n",
    "        # content image\n",
    "        self.content = content\n",
    "        # style image\n",
    "        self.style = style\n",
    "        # final output to be saved\n",
    "        self.x = self.content.clone()\n",
    "        # where to insert loss\n",
    "        self.content_layer = ['conv4']\n",
    "        self.style_layer = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "        # weight to update style and content, should be huge on style, little on content\n",
    "        self.style_weight = style_weight\n",
    "        self.content_weight = content_weight\n",
    "        # pre-trained net\n",
    "        self.vgg = models.vgg19(pretrained=True)\n",
    "        self.loss = nn.MSELoss().to(device)\n",
    "        self.optimizer = optim.LBFGS([self.x])\n",
    "        \n",
    "    def train():\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
